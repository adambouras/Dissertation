---
title: "Methods"
author:
- name: Andrew Heiss
  affiliation: Duke University
  email: andrew.heiss&#x40;duke.edu
date: April 7, 2017
published: "Please download the latest version at [ingoresearch.org/research/](https://ingoresearch.org/research/)."
reference-section-title: References
git-repo: https://github.com/andrewheiss/Dissertation
---


# Global survey of international NGOs

## Definition of international NGO

There is no central database of all international NGOs active in the world, and indeed, creating such a directory is impossible, due to issues with both definitions and logistics. There is no universally accepted definition of "international" or "nongovernmental," and existing directories vary in what counts as an INGO. For instance, the UN's Economic and Social Council (ECOSOC) defines international NGOs as any internationally-focused organization that is not created by an intergovernmental agreement, which essentially designates NGOs as a catch-all category for any organization that is not a purely governmental body [@ecosoc-resolution]. In an effort to narrow this definition, the Yearbook of International Organizations—a widely used source for research on international organizations [see @SmithWest:2005; @Munck:2010; @BarryBellClay:2015; @Murdie:2014; @Johnson:2014; among others]—defines international NGOs based on a set of seven rules related to an entity's organizational structure, purpose, and activity, and adds the additional stipulation that an organization's operations target three or more countries [@ybio-explanation]. 

For the purposes of this study, in an effort to capture the broadest range of potential organizations, I consider an international nongovernmental organization to be any organization that is not incorporated as a governmental entity or as a private firm that conducts advocacy, provides services, or otherwise works in at least *one* country other than the one it is headquartered in. Using this minimalist definition provides several benefits. First, it allows me to bracket the longstanding definitional debate discussed above. While this debate raises important questions about the nature of international NGOs, the scope of their operations, and their role in global politics, it has less bearing on how these organizations are treated by their host countries. Legislation and regulation governing the behavior of international NGOs is not based on whether an organization has official ECOSOC status, works in a certain number of countries, or defines itself as international or transnational. Instead, the legal regime for regulating INGOs in most countries looks at more practical organizational characteristics, such as an organization's organizational structure (members of the board, staff ratios, etc.) or sources of funding, and laws tend to target both domestic and international NGOs simultaneously.

Second, stricter definitions of internationality, such as the Yearbook's requirement that an organization works in at least three countries, omit smaller NGOs that are nonetheless international in scope. Broadening the definition of international NGO allows me to better capture the experiences of these smaller organizations and permits me to explore the effect of organization size and geographic scope on its response to regulations. The number of countries an organization works in likely affects its flexibility—if an INGO works only in one country, it cannot easily shift its resources to another country in response to harsher restrictions, while an INGO with programs in dozens of of countries can likely make more programmatic adjustments.

## Creation of list of international NGOs

As discussed in the introduction to the dissertation, I look at how government regulations affect international NGOs working in two general sectors: freedom of expression, representing more contentious human rights and advocacy-focused organizations, and education, representing ostensibly less contentious service provision organizations. The Yearbook of International Organizations conveniently classifies organizations by issue area, which allowed me to collect contact information for organizations dealing both with freedom of expression (all organizations categorized as "Censorship", "Journalism," and "Media") and education (all organizations categorized as "Education"). The Yearbook also follows a detailed typology of organizational type, distinguishing between various forms of international organization, such as research bodies, intergovernmental bodies, commercial enterprises, and so forth. For this list of international NGOs, I excluded any organization classified as any of the the following types:

- Type I: H (Inactive or dissolved international organizations), J (Recently reported or proposed international organizations), R (Religious orders, fraternities and secular institutes), S (Autonomous conference series), T (Multilateral treaties and agreements), and U (Inactive or dissolved non-conventional bodies)
- Type II: c (conference series), d (dissolved, dormant), e (commercial enterprise), g (intergovernmental), and s (information suspect)
- Type III: Alumni and Veterans, European Union Bodies, FAO Bodies, ILO Bodies, NATO Bodies, Parliaments, Political Parties, Treaties, United Nations Bodies, WHO Bodies, Corporations, Companies, and Intergovernmental Communities 

As noted previously, the Yearbook uses a more restrictive definition of international NGO that limits the pool of possible respondents to larger organizations working in multiple countries. Expanding this initial list of organizations to include smaller organizations is more difficult, however—the Yearbook is hand-curated, carefully organized, and updated annually, and its quality exceeds that of most other online directories of NGOs, which tend to only categorize organizations along broad issue areas (such as human rights or development) and do not distinguish between internationally- and domestically-oriented organizations. To augment the initial Yearbook-based list with smaller organizations, I added information from several additional NGO directories, falling into three broad categories:

- *General international NGOs*: The UN Department of Economic and Social Affairs (DESA) acts as a mediator between the United Nations and civil society organizations granted consultative status with the UN's ECOSOC. DESA maintains the integrated Civil Society Organizations (iCSO) System, a dedicated database of 27,000 DESA- and ECOSOC-affiliated NGOs that have registered themselves with the UN.[^1] The application form for inclusion in the database includes four options for an NGO's geographic scope, which permitted me to select 7,632 apparently international NGOs—I omitted organizations classified as local and national and kept only regional and international organizations. As this database does not indicate which issues organizations work on, I include all apparently international organizations in the sample. 
- *Development international NGOs*: The Directory of Development Organizations (DDO)[^2] is a privately-maintained list of nearly 15,000 development-focused NGOs, including thousands of organizations focused on education issues. The directory categorizes organizations according to their home country, but does not include information about the issues they work on. As such, I include all organizations in the sample.
- *Human rights international NGOs*: I augment the list of freedom of expression organizations by including two directories of human rights-focused NGOs: (1) the Arab Institute of Human Rights directory,[^3] and (2) a database of anti-human trafficking NGOs compiled by @HeissKelley:2016 and the Polaris Project.[^4] 

## Sampling strategy

With the exception of the ECOSOC list, none of these directories indicate where the organizations work—only their organizational headquarters. As such, there is no systematic way to disambiguate international NGOs, as I define them, from domestic NGOs. To account for this, I use an early question in the survey to filter out domestic NGOs.[^5] Organizations that indicate they only work in one country leave the survey early and are not included in this analysis. 

I faced an empirical tradeoff with the survey's sampling strategy. I could attempt to calculate accurate population estimates and boost the survey's inferential power by creating probability-based panels of potential participants, but doing so would reduce the possible number of responses substantially, especially given the impossibility of distinguishing between domestic and international organizations. Additionally, given the composition of the lists, the universe of possible NGO sectors is inherently not representative of the entire INGO sector—the UN's list of ECOSOC-affiliated NGOs is self-selected, and the other lists are domain-based, selecting only organizations focused on education, development, freedom of expression, human rights, and human trafficking. Finally, it was impossible to know how many of the organizations listed in these directories were defunct and unreachable. Sampling from such an unstable population would result in a small number of usable responses. To maximize the chances of identifying the greatest number of *international* organizations in the list, I instead conduct a non-probability list-based internet survey [@AAPOR:2016, 43]. While this decision increases the number of responses, it limits the inferential and statistical power of the sample and tempers the conclusions and findings. Regardless, though results from the survey are not perfectly reflective of the entire global INGO sector, they do reveal important insights and trends about a self-selecting subset of organizations working on education and human rights issues. 

## Survey details

Combining all five of these lists yielded 33,973 potential INGOs (see @tbl:summary-list). A large proportion of these organizations, however, had invalid, outdated, or incomplete information. Prior to conducting the survey, I used an e-mail verification service to confirm that the organization's internet domain name was valid and that the e-mail address listed existed at the domain. More than three-fourths of the final list contained apparently valid organizations (26,772), with wide variation across directories—nearly all the organizations listed in the DDO and in the UN's iCSO list were valid, while less than a third of the organizations in the Yearbook of International Organizations had usable e-mail addresses. Even with this cleaner list, 9,182 e-mail invitations were rejected (or bounced) by their receiving servers, including more than half of the apparently valid DDO organizations. Ultimately, only 17,590 (or 52%) of the complete list of organizations received an e-mail invitation, which indicates significant problems with maintaining up-to-date information in online directories of NGOs. 

\blandscape
\footnotesize
\renewcommand\arraystretch{1.6}
!INCLUDE "../../Output/tables/3-summary-list.md"
\elandscape

Traditional survey-based research will often report a survey's response rate. Response rates are associated with probability samples and rely on knowing the exact size of the survey sample. With non-probability list-based internet surveys, however, it is impossible to know how many potential respondents were exposed to the invitation or how often they were exposed—the only response data known about possible respondents is the number of members invited to the survey and the number of members who respond to and complete the survey. Because of this, response rates are impossible to calculate for this kind of survey [@AAPOR:2016]. Instead, a somewhat comparable participation (or completion) rate can be calculated, dividing the number of usable responses by the total number of initial survey invitations [@CallegaroDiSogra:2008, 1021–22]. The participation rate cannot be used as a measure of possible nonresponse error, but it can indicate the overall efficiency of the panel [@AAPOR:2016, 49]. 

Of the 17,590 organizations that potentially received the initial survey invitation, 537 completed the survey, 104 provided a partial (but usable) response,[^6] 311 ended the survey early, and the remainder indicated that they did not work internationally or did not respond, either because they self-selected out without answering any questions (since the first page of the survey indicated that the survey was for international NGOs), or because they did not open the invitation e-mail. This yielded a participation rate of 3.8%, which is low, but to be expected, given that it was impossible to specifically target international NGOs prior to conducting the survey. The questions in the survey were divided into two general sections related to (1) respondents' organizations and (2) their work in one of the countries they target. I allowed respondents to answer country-specific questions for multiple countries if they wanted, but only eighteen provided responses for more than one country. The survey thus resulted in 641 usable organization-level responses and 659 country-level responses.

## Analytic strategy and possible biases

Online surveys pose other methodological challenges beyond issues of sampling. My list inherently omits any international NGOs without an active English-based online presence, ignoring organizations that do not engage with the UN or other English-centered umbrella organization, organizations that lack technical capacity to maintain a current website or access the internet to respond to the survey, or organizations that purposely do not publish their information online. Accordingly, this survey does not represent all INGOs. Though it is impossible to tell exactly how respondents and nonrespondents differed in their choice to complete the survey, as I do not have complete information about the pool of potential respondents, more European and American NGOs responded than those based in Asia and Africa, likely because of these technological and linguistic barriers—of the organizations in the master database with a known headquarters location, roughly 2.5% of Asian NGOs and 3% of African NGOs responded, in contrast to nearly 6% of both European and American NGOs.[^7]

I took several steps to address these biases and threats to validity, based on the methods and recommendations of others [@Buthe:2011; @EdwardsRobertsClarke:2009; @HeissKelley:2016]. After cleaning the initial list of e-mails, I sent each potential respondent an initial invitation, followed up with a reminder two weeks later, and a final reminder after another two weeks.[^8] To reduce language barriers, respondents were encouraged to answer all free questions in their native language. Because the survey deals with sensitive questions about organizational strategy in potentially precarious political contexts, respondents were informed that their responses would be kept anonymous. To maintain anonymity when discussing the results of the survey, each respondent was assigned a randomly assigned four-digit ID number, and quotes from the free response questions were stripped of potentially identifying information. The exact countries where respondents work were also anonymized and are offered instead as general regions (e.g. Ghana is reported as West Africa; Thailand is reported as Southeast Asia).

The nature of the population of INGOs poses an additional challenge for analyzing organizational strategy. To isolate the effect of country-level policies on INGOs, the survey asks organizations about their experiences working in *one* country, yet many INGOs work in multiple countries. An early question in the survey asked respondents to identify all the countries their has organization worked in, and later in the survey, respondents were asked to choose one of those pre-selected countries to answer a set of country-specific questions. This introduces additional bias into the survey responses—especially for organizations working in dozens of different countries—since respondents were given some choice about their responses. However, allowing for self-selection of target country was, to some extent, unavoidable given how little was known about the sample population *a priori*. Randomly offering one country from the subset of countries organizations identified previously could present a respondent with a country in which an organization engages in only minor work (e.g. an organization that attends an annual conference in one country may indicate that they have worked there), yielding less-than-useful country-level responses. 

Furthermore, to avoid priming respondents' opinions of their experiences with host governments, I did not ask organizations to choose the country they felt most restricted working in (though that was the main purpose of the survey)—the survey simply asked respondents to choose one of the previously selected countries. This introduces a concern that organizations may have chosen to answer questions about easier, less restrictive countries. Nearly half of respondents answered questions about a country that had a less restrictive civil society regulatory environment (as measured by the CSRE index from chapter 2) than the average CSRE across their total portfolio of host countries, 35% answered about countries that were more restrictive than the average CSRE, and 21% answered about countries with the same level of restrictiveness as the average (see @fig:selected-easier). To some extent, respondents did tend to provide answers about their work in less restrictive countries compared to their total portfolio, possibly to avoid answering more difficult questions.

![Average CSRE in country about which organization answered vs. all countries organization selected](../../Output/figures/3-easier-harder){#fig:selected-easier}

That said, there is some evidence that respondents answered questions about the countries with which they were most familiar, regardless of the restrictiveness of the regulatory environment. Respondents headquartered in specific regions tended to answer questions about their work in countries in a way that reflected general patterns for that region. For instance, that fit a general pattern for INGOs based in their same region. For instance, 44% of all Europe-based respondents indicated that they conduct work in other European countries, with 23% working in Asia, 18% in Africa, and 14% in the Americas (see @fig:regions-sankey). Correspondingly, 46% of Europe-based respondents answered questions about their work in Europe, 20% about Asia, 20% in Africa, and 14% in the Americas. This distribution closely mirrors that of the countries these INGOs had selected and shows that, at least at a regional level, organizations did not answer questions about their work in a less restrictive region (such as Europe). This pattern of similarity holds for INGOs working in all other regions, with the exception of Africa-based INGOs—while 66% of African INGOs indicated working in other African countries, 83% answered questions about their work in other African countries, indicating that respondents likely chose to answer questions about countries that were most familiar and similar to their home countries and not necessarily because of the CSRE. 

<div id="fig:regions-sankey">
![Countries recipients selected](../../Output/figures/3-countries-selected){#fig:regions-sankey-selected}

![Countries about which recipients answered](../../Output/figures/3-countries-answered){#fig:regions-sankey-answered}

Patterns of headquarters and host country regions for countries about which organizations selected and answered
</div>

Since the survey was designed to not have strong statistical or inferential power (opting to maximize possible international NGO response instead), the findings are not fully representative of all INGOs. Additionally, several INGOs explicitly opted to not take the survey for fears of political reprisal, despite the promised privacy safeguards. As such, the results omit the most at-risk organizations. Despite this, the findings highlight important trends in how INGOs react to the regulatory environments of their host countries and provide useful (albeit imperfect) tests of the theory of amicable contempt. I report basic summary statistics and cross-tabulations of survey responses and I use Bayesian inferential statistics to check for differences in means and associations within responses. Bayesian methods are especially appropriate for making tentative exploratory inferences from this kind of data, particularly when combined with data visualizations and graphs [@Gelman:2003], and accordingly, I rely heavily on statistical graphics when making inferences. As with previous statistical chapters, I use weakly informative prior distributions for sample parameters and I obtain the posterior distribution of the CSRE with Markov Chain Monte Carlo (MCMC) sampling and simulate values from the joint posterior distribution of sample parameters.[^9]

In the absence of strong statistical power, I supplement inferences with interpretive analysis of the survey's free response answers. Only 19 respondents (2.8%) declined to answer any of the survey's 36 open-ended questions, and most answered between 8–16 questions, resulting in a sizable corpus of qualitative insights into INGO experiences with their host governments. Where possible, I quote extensively from these responses to provide deeper anecdotal support of organizations's experiences and decisions working with the governments of their target countries.

[^1]:	[http://esango.un.org/civilsociety/](http://esango.un.org/civilsociety/)

[^2]:	[http://www.devdir.org](http://www.devdir.org)

[^3]:	[http://www.aihr-resourcescenter.org/](http://www.aihr-resourcescenter.org/)

[^4]:	[http://globalmodernslavery.org](http://globalmodernslavery.org)

[^5]:	Q2.4: Does your organization work in a country other than the country in which it is headquartered?

[^6]:	To count as a valid partial response, a responded had to answer at least 20 questions in the survey, and at least 6 had to come from the section asking about the organization's work in a specific country.

[^7]:	The difference between these proportions is highly significant ($P(\text{\% Africa} - \text{\% Europe} < 0) = 1$).

[^8]:	For technical details on how the invitation was sent and designed, see [https://notebook.andrewheiss.com/project/diss-ingos-in-autocracies/survey-technical-details/](https://notebook.andrewheiss.com/project/diss-ingos-in-autocracies/survey-technical-details/).

[^9]:	I use Stan [@stan] through R [@rstan; @r-project] to generate 4 MCMC chains with 2,000 iterations in each chain, 1,000 of which are used for warmup. All chains converge; I assess convergence with visual inspection, and diagnostic plots are included the dissertation appendix.

	I use the medians of the simulated values from the MCMC samples as coefficient estimates, and use the 2.5% and 97.5% quantiles as lower and upper limits for 95% credible intervals. Finally, I declare an effect statistically significant if the posterior probability of being different from zero is larger than 0.95.